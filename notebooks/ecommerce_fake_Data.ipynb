{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\client\\anaconda3\\envs\\automation\\lib\\site-packages (20.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\client\\anaconda3\\envs\\automation\\lib\\site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\client\\anaconda3\\envs\\automation\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install faker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Function to generate a batch of customer data\n",
    "def generate_customer_data(batch_size):\n",
    "    data = []\n",
    "    for _ in range(batch_size):\n",
    "        customer_id = fake.unique.uuid4()\n",
    "        name = fake.name()\n",
    "        email = fake.unique.email()\n",
    "        phone = fake.phone_number()\n",
    "        address = fake.address()\n",
    "        registration_date = fake.date_between(start_date='-5y', end_date='today')\n",
    "        last_login = registration_date + timedelta(days=random.randint(1, 365))\n",
    "        last_login = min(last_login, datetime.now().date())\n",
    "\n",
    "        data.append([customer_id, name, email, phone, address, registration_date, last_login])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=[\"CustomerID\", \"Name\", \"Email\", \"Phone\", \"Address\", \"RegistrationDate\", \"LastLogin\"])\n",
    "\n",
    "# Generate a small batch for demonstration\n",
    "demo_batch = generate_customer_data(10)\n",
    "# Function to generate the complete dataset in batches and save to CSV\n",
    "\n",
    "def generate_full_dataset(total_customers, batch_size, filename):\n",
    "    all_data = []\n",
    "    for _ in range(0, total_customers, batch_size):\n",
    "        batch_data = generate_customer_data(min(batch_size, total_customers - len(all_data)))\n",
    "        all_data.append(batch_data)\n",
    "\n",
    "    full_data = pd.concat(all_data, ignore_index=True)\n",
    "    full_data.to_csv(filename, index=False)\n",
    "    return full_data\n",
    "\n",
    "# Generate full dataset for 75,000 customers\n",
    "# Due to memory and processing constraints, I'll use a smaller batch size and demonstrate with a smaller number\n",
    "demo_total_customers = 30000  # For demonstration purposes\n",
    "batch_size = 10\n",
    "file_name = './data/CustomerData.csv'\n",
    "\n",
    "full_dataset = generate_full_dataset(demo_total_customers, batch_size, file_name)\n",
    "full_dataset.head(10)  # Displaying the first 10 rows of the generated data for demonstration purposes\n",
    "full_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate synthetic inventory data, referencing the product data\n",
    "\n",
    "def generate_inventory(num_inventory_records, products_df):\n",
    "    inventory_data = []\n",
    "    \n",
    "    for _ in range(num_inventory_records):\n",
    "        inventory_id = fake.unique.random_int(min=1, max=99999)\n",
    "        # Select a random ProductID from the previously generated products data\n",
    "        product_id = random.choice(products_df['ProductID'].tolist())\n",
    "        # QuantityAvailable will be a random number within the stock level range of the product\n",
    "        product_stock = products_df[products_df['ProductID'] == product_id].iloc[0]['StockLevel']\n",
    "        quantity_available = random.randint(0, product_stock)\n",
    "        # ReorderLevel will be a random number less than QuantityAvailable to simulate a realistic reorder trigger\n",
    "        reorder_level = random.randint(0, quantity_available)\n",
    "        # LastReorderDate will be in the past year\n",
    "        last_reorder_date = fake.date_between(start_date='-1y', end_date='today')\n",
    "        \n",
    "        inventory_data.append({\n",
    "            \"InventoryID\": inventory_id,\n",
    "            \"ProductID\": product_id,\n",
    "            \"QuantityAvailable\": quantity_available,\n",
    "            \"ReorderLevel\": reorder_level,\n",
    "            \"LastReorderDate\": last_reorder_date\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(inventory_data)\n",
    "\n",
    "# Load the products data to ensure we are referencing existing ProductIDs\n",
    "products_df_loaded = pd.read_csv('./data/products.csv')\n",
    "\n",
    "# Generate inventory records for each product\n",
    "num_inventory_records = products_df_loaded.shape[0]\n",
    "\n",
    "# Generate the inventory data\n",
    "inventory_df = generate_inventory(num_inventory_records, products_df_loaded)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "inventory_csv_file_path = './data/inventory.csv'\n",
    "inventory_df.to_csv(inventory_csv_file_path, index=False)\n",
    "\n",
    "inventory_csv_file_path, num_inventory_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shipping rates generation\n",
    "shipments_df = pd.read_csv('./data/shipments.csv')\n",
    "def generate_shipping_rates(num_records, shipments_df):\n",
    "    shipping_rates_data = []\n",
    "    for _ in range(num_records):\n",
    "        shipping_rate_id = fake.unique.random_int(min=1, max=9999999)\n",
    "        shipment_id = random.choice(shipments_df['ShipmentID'].tolist())\n",
    "        shipping_date = fake.date_between(start_date='-2y', end_date='today')\n",
    "        shipping_rate = round(random.uniform(5, 50), 2)  # Shipping rate between $5 and $50\n",
    "        \n",
    "        shipping_rates_data.append({\n",
    "            \"ShippingRateID\": shipping_rate_id,\n",
    "            \"ShipmentID\": shipment_id,\n",
    "            \"ShippingDate\": shipping_date,\n",
    "            \"ShippingRate\": shipping_rate\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(shipping_rates_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tesa(n,x):\n",
    "    lst = []\n",
    "    for i in range(n):\n",
    "        lst.append(x)\n",
    "    return lst\n",
    "\n",
    "\n",
    "\n",
    "def tesb(n1,x1):\n",
    "    n=n1\n",
    "    x=x1\n",
    "    lst_2 = [ ]\n",
    "    for i in range(n1):\n",
    "        lst_2.append(tesa(n,x))\n",
    "    return lst_2\n",
    "    lst_2.append(lst)\n",
    "    print(lst_2)\n",
    "\n",
    "tesb(20,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the DataFrame\n",
    "orders_df = pd.read_csv('../data/csv/orders_v1.csv')\n",
    "def Status_updater(orders_df):\n",
    "    orders_df['Status'] = np.nan\n",
    "    current_date = date.today()\n",
    "    orders_df['OrderDate'] = pd.to_datetime(orders_df['OrderDate']).dt.date\n",
    "    def update_Status_based_on_date(row):\n",
    "        days_since_order = (current_date - row['OrderDate']).days\n",
    "        if days_since_order <=2:\n",
    "            return 'Processing'\n",
    "        elif days_since_order >2 and days_since_order <= 25:\n",
    "            return 'Shipped' \n",
    "        elif days_since_order >25:\n",
    "            return 'Delivered'\n",
    "        return row['Status']\n",
    "\n",
    "    def mark_cancelled(row):\n",
    "        days_since_order = (current_date - row['OrderDate']).days\n",
    "        if row['Status'] == 'Processing' and days_since_order <= 3:\n",
    "            # Assuming a 5% chance of an order being cancelled\n",
    "            if np.random.rand() < 0.05:\n",
    "                return 'Cancelled'\n",
    "        return row['Status']\n",
    "\n",
    "    def mark_returned(row):\n",
    "        days_since_order = (current_date - row['OrderDate']).days \n",
    "        if row['Status'] == 'Delivered' and days_since_order <= 30:\n",
    "            # Assuming a 10% chance of a Delivered order being returned\n",
    "            if np.random.rand() < 0.10:\n",
    "                return 'Returned'\n",
    "        return row['Status']\n",
    "\n",
    "    # Update Statuses for cancellation and returns\n",
    "    orders_df['Status'] = orders_df.apply(update_Status_based_on_date, axis=1)\n",
    "    orders_df['Status'] = orders_df.apply(mark_cancelled, axis=1)\n",
    "    orders_df['Status'] = orders_df.apply(mark_returned, axis=1)\n",
    "    \n",
    "    return orders_df\n",
    "\n",
    "\n",
    "Status_updater(orders_df)\n",
    "\n",
    "# if if the difference in days is less than 20 and the current Status is 'returned' then update the Status to 'Processing'\n",
    "# Save the updated DataFrame\n",
    "orders_df['Status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data\n",
    "orders_df = pd.read_csv('../data/csv/v2/orders_v2.csv')\n",
    "order_details_df = pd.read_csv('./data/csv/v2/order_details.csv')\n",
    "fake= Faker()\n",
    "order_details=order_details_df.merge(orders_df, on='OrderID', how='left')\n",
    "order_details = order_details[order_details['Status'].isin(['Shipped', 'Delivered'])]\n",
    "reasons_ratio = [0.4, 0.06, 0.04]\n",
    "# Define a new function that will create an inventory log based on the product data and order details to simulate inventory movement.\n",
    "def generate_inventory_log(num_records, orders_data):\n",
    "    inventory_log_data = []\n",
    "    reasons = [\"Sale\", \"Restock\", \"Adjustment\", \"Damage\"]\n",
    "    \n",
    "    for col, row in order_details.iterrows():\n",
    "    # Generate log entries for product sales based on order details\n",
    "        inventory_log_id = fake.uuid4()\n",
    "        product_id = order_details['ProductID']\n",
    "        quantity_change = -order_details['Quantity']  # Negative for sales\n",
    "        change_date = order_details['OrderDate']\n",
    "        inventory_log_data.append({\n",
    "            \"InventoryLogID\": inventory_log_id,\n",
    "            \"ProductID\": product_id,\n",
    "            \"QuantityChange\": quantity_change,\n",
    "            \"ChangeDate\": change_date,\n",
    "            \"Reason\": \"Sale\"\n",
    "        })\n",
    "\n",
    "    # Generate log entries for inventory changes not related to sales\n",
    "    for reason, count in zip(reasons[1:], reasons_ratio):\n",
    "        for _ in range(int(num_records)):  # Ratio for each of the other reasons\n",
    "            inventory_log_id = fake.uuid4()\n",
    "            product_id = random.choice(order_details['ProductID'].tolist())\n",
    "            # Restock gets positive quantity, Adjustment and Damage get negative quantity\n",
    "            quantity_change = random.randint(1, 20) if reason == \"Restock\" else random.randint(-10, -1)\n",
    "            change_date = fake.date_between(start_date='-2y', end_date='today')\n",
    "            \n",
    "            inventory_log_data.append({\n",
    "                \"InventoryLogID\": inventory_log_id,\n",
    "                \"ProductID\": product_id,\n",
    "                \"QuantityChange\": quantity_change,\n",
    "                \"ChangeDate\": change_date,\n",
    "                \"Reason\": reason\n",
    "            })\n",
    "    return pd.DataFrame(inventory_log_data)\n",
    "\n",
    "\n",
    "# Generate the inventory log based on products and order details\n",
    "num_records = num_sales + (num_sales * sum(reasons_ratio))  # Total number of inventory log records\n",
    "inventory_log_df = generate_inventory_log(\n",
    "    num_records, order_details\n",
    ")\n",
    "\n",
    "# Save the inventory log data to a CSV file\n",
    "inventory_log_csv_file_path = './data/inventory_log_data.csv'\n",
    "inventory_log_df.to_csv(inventory_log_csv_file_path, index=False)\n",
    "\n",
    "# Generate the inventory table based on the inventory log\n",
    "inventory_df = inventory_log_df.groupby('ProductID')['QuantityChange'].sum().reset_index()\n",
    "inventory_df.rename(columns={'QuantityChange': 'QuantityAvailable'}, inplace=True)\n",
    "# Add an InventoryID column\n",
    "inventory_df['InventoryID'] = range(1, len(inventory_df) + 1)\n",
    "\n",
    "# Save the inventory data to a CSV file\n",
    "inventory_csv_file_path = './data/inventory_data.csv'\n",
    "inventory_df.to_csv(inventory_csv_file_path, index=False)\n",
    "\n",
    "inventory_log_csv_file_path, inventory_csv_file_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
